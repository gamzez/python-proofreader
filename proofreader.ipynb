{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import re\n",
    "import string\n",
    "import numpy as np \n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#read the txt file contains OpenAI API key\n",
    "with open('openai_api_key.txt') as f:\n",
    "    api_key = f.readline()\n",
    "openai.api_key = api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proofread(text):\n",
    "    system_role = \"Korrigiere den folgenden deutschen Text und gib mir die korrigierte Version. Mach keine Erklärungen, gib nur den korrigierten Text zurück. Wenn der Text bereits korrekt ist, gib den Originaltext zurück\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ]\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    chat_response = completion.choices[0].message.content \n",
    "    return chat_response\n",
    "\n",
    "def remove_commas_and_dots(text):\n",
    "    return text.replace(',', '').replace('.', '')\n",
    "\n",
    "def remove_space_before_punctuation(text):\n",
    "    pattern = r'\\s+([.?!,:;])'\n",
    "    return re.sub(pattern, r'\\1', text)\n",
    "\n",
    "def count_words(s):\n",
    "    return sum([i.strip(string.punctuation).isalpha() for i in s.split()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grammarly(text_wErrors):\n",
    "    # print(\"\\n\\n\\n\\n\\n\\n\\n\")\n",
    "    # print(\"GRAMMARLY\")\n",
    "    # print(\"#########\")\n",
    "    # print(f\"text_wErrors {text_wErrors}\")\n",
    "    text_wErrors = remove_space_before_punctuation(text_wErrors)\n",
    "    # print(f\"text_wErrors {text_wErrors}\")\n",
    "    text_corrected = proofread(text_wErrors)\n",
    "    # print(f\"text_corrected {text_corrected}\")\n",
    "    \n",
    "    # Compare texts without commas and dots for isError\n",
    "    text_wErrors_no_commas_dots = remove_commas_and_dots(text_wErrors)\n",
    "    # print(f\"text_wErrors_no_commas_dots {text_wErrors_no_commas_dots}\")\n",
    "    text_corrected_no_commas_dots = remove_commas_and_dots(text_corrected)\n",
    "    # print(f\"text_corrected_no_commas_dots {text_corrected_no_commas_dots}\")\n",
    "    \n",
    "    isWordCountSame = np.abs(count_words(text_wErrors_no_commas_dots) - count_words(text_corrected_no_commas_dots)) < 2\n",
    "    isError =  isWordCountSame and (text_corrected_no_commas_dots.lower() != text_wErrors_no_commas_dots.lower())\n",
    "    # print(f\"isError {isError}\")\n",
    "    text_corrected = remove_space_before_punctuation(text_corrected)\n",
    "\n",
    "    # Tokenize the texts, treating hyphenated words as single tokens\n",
    "    tokens1 = re.findall(r'\\w+(?:-\\w+)*\\.?|\\.', text_wErrors)\n",
    "    tokens2 = re.findall(r'\\w+(?:-\\w+)*\\.?|\\.', text_corrected)\n",
    "\n",
    "    # Create a Differ object\n",
    "    d = difflib.Differ()\n",
    "\n",
    "    # Compare the tokens\n",
    "    diff = list(d.compare(tokens1, tokens2))\n",
    "\n",
    "    # Reconstruct the texts with markers\n",
    "    text_with_removed_markers = []\n",
    "    text_with_added_markers = []\n",
    "    for token in diff:\n",
    "        if token.startswith('- '):\n",
    "            text_with_removed_markers.append('-' + token[2:] + '-')\n",
    "        elif token.startswith('+ '):\n",
    "            text_with_added_markers.append('<' + token[2:] + '>')\n",
    "        elif token.startswith('  '):\n",
    "            text_with_removed_markers.append(token[2:])\n",
    "            text_with_added_markers.append(token[2:])\n",
    "\n",
    "    reconstructed_original = ' '.join(text_with_removed_markers)\n",
    "    reconstructed_corrected = ' '.join(text_with_added_markers)\n",
    "    return bool(isError), reconstructed_original, reconstructed_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, '-ich- liebe dich', '<Ich> liebe dich')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammarly('ich liebe dich')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
